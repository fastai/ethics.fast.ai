# Lesson 5.3: Losing the Forest for the Trees, guest lecture by Ali Alkhatib

We turn our messy world into data to reason about it and to inform actions. That's become a growing problem as we build systems directly out of that data. People respond and begin performing for the algorithms that dictate our lives. CADE Research Fellow Ali Alkhatib draws on the history of HCI, James Scott's Seeing Like a State, and current issues in data ethics in discussing the issues that arise when we uncritically build algorithmic systems on historical foundations of greed exploitation, and harm.

## Required Reading:
Zeynep Tufekci, [How social media took us from Tahrir Square to Donald Trump](https://www.technologyreview.com/s/611806/how-social-media-took-us-from-tahrir-square-to-donald-trump/)
James Grimmelman, [The Platform is the Message](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3132758)
Rachel Thomas, [The Problem with Metrics](https://www.fast.ai/2019/09/24/metrics/)
Tim O’Reilly, [The fundamental problem with Silicon Valley’s favorite growth strategy](https://qz.com/1540608/the-problem-with-silicon-valleys-obsession-with-blitzscaling-growth/)
Ali Alkhatib, [Anthropological/Artificial Intelligence & the Institute for Human-centered AI](https://ali-alkhatib.com/blog/anthropological-intelligence)

## Optional Reading:
Tom Slee, [The incompatible incentives of private sector AI](https://tomslee.github.io/publication/oup_private_sector_ai/)

